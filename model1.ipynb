{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9056968",
   "metadata": {},
   "source": [
    "If best_fusion_multi.pth is available, no need to train the NN again, just run cells 1-2 and 12-14 to get the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d9af8",
   "metadata": {},
   "source": [
    "1. Install and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95edcb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your environment already has these, you can skip installs.\n",
    "# !pip install torch torchvision pandas scikit-learn tqdm --quiet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a0ac9e",
   "metadata": {},
   "source": [
    "2. Configuration (paths, target list, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e81f8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- Paths ---\n",
    "TRAIN_CSV = \"train.csv\"\n",
    "TEST_CSV = \"test.csv\"\n",
    "TRAIN_IMG_ROOT = pathlib.Path(\"train\")  # not prepended if CSV has full/relative paths; we'll handle both\n",
    "TEST_IMG_ROOT = pathlib.Path(\"test\")\n",
    "SAMPLE_SUBMISSION = \"sample_submission.csv\"  # optional template; if missing we'll build from test.csv\n",
    "\n",
    "# --- Targets (expected target_name values) ---\n",
    "TARGET_NAMES = [\n",
    "    \"Dry_Clover_g\",\n",
    "    \"Dry_Dead_g\",\n",
    "    \"Dry_Green_g\",\n",
    "    \"Dry_Total_g\",\n",
    "    \"GDM_g\"\n",
    "]\n",
    "\n",
    "# --- Training hyperparameters (tweak as needed) ---\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4\n",
    "EPOCHS = 2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "WORKERS = 0\n",
    "print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e056f41",
   "metadata": {},
   "source": [
    "3. Load & pivot train.csv into one row per sample (with tabular features + multi-target vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109fa281",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(TRAIN_CSV)\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1004d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure image_path is string\n",
    "train_raw[\"image_path\"] = train_raw[\"image_path\"].astype(str)\n",
    "\n",
    "# We'll build a per-sample table:\n",
    "# - take the first image_path found for each sample_id (CSV may duplicate)\n",
    "# - gather tabular features from the first row for that sample (Sampling_Date, State, Species, Pre_GSHH_NDVI, Height_Ave_cm)\n",
    "# - pivot target values into columns (one column per target_name)\n",
    "\n",
    "# pivot targets\n",
    "targets_pivot = train_raw.pivot_table(\n",
    "    index=\"sample_id\",\n",
    "    columns=\"target_name\",\n",
    "    values=\"target\",\n",
    "    aggfunc=\"first\"\n",
    ")\n",
    "\n",
    "# Get one row per sample for other columns (image path and metadata) by taking first occurrence\n",
    "meta_cols = [\"image_path\", \"Sampling_Date\", \"State\", \"Species\", \"Pre_GSHH_NDVI\", \"Height_Ave_cm\"]\n",
    "meta = train_raw.groupby(\"sample_id\").first()[meta_cols]\n",
    "\n",
    "# join\n",
    "train_samples = meta.join(targets_pivot)\n",
    "train_samples = train_samples.reset_index()\n",
    "print(\"Number of unique samples:\", len(train_samples))\n",
    "train_samples.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5705cf9c",
   "metadata": {},
   "source": [
    "4. Preprocess tabular features (date cyclic, one-hot, scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909cecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date cyclic encoding (day of year -> sin/cos)\n",
    "def add_date_features(df, date_col=\"Sampling_Date\"):\n",
    "    # parse dates safely:\n",
    "    dates = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    dayofyear = dates.dt.dayofyear.fillna(1).astype(int)  # default to 1 if missing\n",
    "    df[\"date_sin\"] = np.sin(2 * np.pi * dayofyear / 365.25)\n",
    "    df[\"date_cos\"] = np.cos(2 * np.pi * dayofyear / 365.25)\n",
    "    return df\n",
    "\n",
    "train_samples = add_date_features(train_samples)\n",
    "\n",
    "# Fit OneHotEncoder on State and Species (train only)\n",
    "cat_cols = [\"State\", \"Species\"]\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "enc.fit(train_samples[cat_cols].fillna(\"\"))\n",
    "\n",
    "# Numeric features to scale\n",
    "num_cols = [\"Pre_GSHH_NDVI\", \"Height_Ave_cm\"]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_samples[num_cols].fillna(0).values)\n",
    "\n",
    "# Build tabular matrix for train samples (order matters)\n",
    "def build_tabular_matrix(df, enc, scaler):\n",
    "    # date sin/cos\n",
    "    date_part = df[[\"date_sin\", \"date_cos\"]].values.astype(float)\n",
    "    # numeric scaled\n",
    "    num_part = df[num_cols].fillna(0).values.astype(float)\n",
    "    num_part_scaled = scaler.transform(num_part)\n",
    "    # categorical one-hot (enc handles unknowns if present)\n",
    "    cat_part = enc.transform(df[cat_cols].fillna(\"\"))\n",
    "    # final concat\n",
    "    return np.hstack([date_part, num_part_scaled, cat_part]).astype(np.float32)\n",
    "\n",
    "tabular_all = build_tabular_matrix(train_samples, enc, scaler)\n",
    "print(\"Tabular shape:\", tabular_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2109f7",
   "metadata": {},
   "source": [
    "5. Build multi-target arrays and mask (for missing targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target matrix with ordering given by TARGET_NAMES\n",
    "def build_targets_and_mask(df, target_names):\n",
    "    n = len(df)\n",
    "    m = len(target_names)\n",
    "    targets = np.zeros((n, m), dtype=np.float32)\n",
    "    mask = np.zeros((n, m), dtype=np.float32)  # 1 if target exists, 0 if missing\n",
    "    for i, row in df.iterrows():\n",
    "        for j, tname in enumerate(target_names):\n",
    "            val = row.get(tname, np.nan)\n",
    "            if pd.notna(val):\n",
    "                targets[i, j] = float(val)\n",
    "                mask[i, j] = 1.0\n",
    "    return targets, mask\n",
    "\n",
    "targets_all, mask_all = build_targets_and_mask(train_samples, TARGET_NAMES)\n",
    "print(\"Targets shape:\", targets_all.shape, \"Mask shape:\", mask_all.shape)\n",
    "# quick check counts\n",
    "print(\"Observed target counts per output:\", mask_all.sum(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e9fc2",
   "metadata": {},
   "source": [
    "6. Train / Validation split (split by sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split samples (we'll split by index/sample not per-row)\n",
    "train_idx, val_idx = train_test_split(np.arange(len(train_samples)), test_size=0.2, random_state=42)\n",
    "\n",
    "# prepare arrays\n",
    "X_tab_train = tabular_all[train_idx]\n",
    "X_tab_val = tabular_all[val_idx]\n",
    "y_train = targets_all[train_idx]\n",
    "y_val = targets_all[val_idx]\n",
    "mask_train = mask_all[train_idx]\n",
    "mask_val = mask_all[val_idx]\n",
    "df_train = train_samples.iloc[train_idx].reset_index(drop=True)\n",
    "df_val = train_samples.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print(\"Train samples:\", len(df_train), \"Val samples:\", len(df_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae34be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = 0\n",
    "for p in df_train[\"image_path\"].head(50):\n",
    "    if not pathlib.Path(p).exists():\n",
    "        print(\"Missing:\", p)\n",
    "        bad += 1\n",
    "\n",
    "print(\"Bad paths:\", bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceb22b7",
   "metadata": {},
   "source": [
    "7. Dataset classes (train/val & test) — robust path handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTargetPastureDataset(Dataset):\n",
    "    def __init__(self, df, tabular_array, targets_array=None, mask_array=None, transform=None, img_root=None):\n",
    "        \"\"\"\n",
    "        df: DataFrame with sample rows (must include image_path)\n",
    "        tabular_array: numpy array aligned with df rows\n",
    "        targets_array: numpy array (N, M) or None for test\n",
    "        mask_array: numpy array (N, M) same shape as targets (1 where present)\n",
    "        transform: image transform\n",
    "        img_root: pathlib.Path root folder to prepend IF image_path is relative missing folder\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tab = torch.tensor(tabular_array, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets_array, dtype=torch.float32) if targets_array is not None else None\n",
    "        self.mask = torch.tensor(mask_array, dtype=torch.float32) if mask_array is not None else None\n",
    "        self.transform = transform\n",
    "        self.img_root = pathlib.Path(img_root) if img_root is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _resolve_path(self, raw_path):\n",
    "        # raw_path may already include train/ or be just filename.\n",
    "        p = pathlib.Path(raw_path)\n",
    "        if p.exists():\n",
    "            return p\n",
    "        # try with img_root prepended if provided\n",
    "        if self.img_root is not None:\n",
    "            p2 = self.img_root / p\n",
    "            if p2.exists():\n",
    "                return p2\n",
    "        # try filename only in img_root\n",
    "        if self.img_root is not None and \"/\" in str(raw_path):\n",
    "            # try last part\n",
    "            last = pathlib.Path(raw_path).name\n",
    "            p3 = self.img_root / last\n",
    "            if p3.exists():\n",
    "                return p3\n",
    "        # fallback: return original path (will raise later)\n",
    "        return p\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self._resolve_path(row[\"image_path\"])\n",
    "        if not img_path.exists():\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        img = Image.open(str(img_path)).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        tab = self.tab[idx]\n",
    "        if self.targets is not None:\n",
    "            y = self.targets[idx]\n",
    "            m = self.mask[idx]\n",
    "            return img, tab, y, m\n",
    "        else:\n",
    "            # test\n",
    "            return img, tab, row[\"sample_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23426e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPastureDataset(Dataset):\n",
    "    def __init__(self, df, tabular_array, transform=None, img_root=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tab = torch.tensor(tabular_array, dtype=torch.float32)\n",
    "        self.transform = transform\n",
    "        self.img_root = pathlib.Path(img_root) if img_root is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _resolve_path(self, raw_path):\n",
    "        p = pathlib.Path(raw_path)\n",
    "        if p.exists():\n",
    "            return p\n",
    "        if self.img_root is not None:\n",
    "            p2 = self.img_root / p\n",
    "            if p2.exists():\n",
    "                return p2\n",
    "            last = pathlib.Path(raw_path).name\n",
    "            p3 = self.img_root / last\n",
    "            if p3.exists():\n",
    "                return p3\n",
    "        return p\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self._resolve_path(row[\"image_path\"])\n",
    "        if not img_path.exists():\n",
    "            raise FileNotFoundError(f\"Test image not found: {img_path}\")\n",
    "        img = Image.open(str(img_path)).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        tab = self.tab[idx]\n",
    "        return img, tab, row[\"sample_id\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d059ae",
   "metadata": {},
   "source": [
    "8. Transforms & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea43eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_dataset = MultiTargetPastureDataset(df_train, X_tab_train, y_train, mask_train, transform=train_transform, img_root=TRAIN_IMG_ROOT)\n",
    "val_dataset   = MultiTargetPastureDataset(df_val,   X_tab_val,   y_val,   mask_val,   transform=val_transform,   img_root=TRAIN_IMG_ROOT)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"Train batches:\", len(train_loader), \"Val batches:\", len(val_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93dac1a",
   "metadata": {},
   "source": [
    "9. Model: EfficientNet backbone + tabular MLP + fusion head (outputs 5 values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe6aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionMultiOutputModel(nn.Module):\n",
    "    def __init__(self, tabular_dim, num_outputs=len(TARGET_NAMES), backbone_name=\"efficientnet_b0\", fusion_hidden=256):\n",
    "        super().__init__()\n",
    "        if backbone_name == \"efficientnet_b0\":\n",
    "            # torchvision EfficientNetB0\n",
    "            self.backbone = models.efficientnet_b0(pretrained=True)\n",
    "            # remove classifier\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            image_feat_dim = 1280\n",
    "        else:\n",
    "            raise ValueError(\"Only efficientnet_b0 implemented; change if desired\")\n",
    "\n",
    "        # tabular MLP\n",
    "        self.tab_mlp = nn.Sequential(\n",
    "            nn.Linear(tabular_dim, max(32, tabular_dim*2)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(max(32, tabular_dim*2)),\n",
    "            nn.Linear(max(32, tabular_dim*2), 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # fusion head\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(image_feat_dim + 64, fusion_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(fusion_hidden),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(fusion_hidden, fusion_hidden//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fusion_hidden//2, num_outputs)  # multi-output\n",
    "        )\n",
    "\n",
    "    def forward(self, img, tab):\n",
    "        img_feat = self.backbone(img)\n",
    "        tab_feat = self.tab_mlp(tab)\n",
    "        x = torch.cat([img_feat, tab_feat], dim=1)\n",
    "        out = self.fusion(x)\n",
    "        return out\n",
    "\n",
    "# instantiate\n",
    "tab_dim = X_tab_train.shape[1]\n",
    "model = FusionMultiOutputModel(tabular_dim=tab_dim).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bd01e2",
   "metadata": {},
   "source": [
    "10. Loss that respects mask (MAE only where mask==1) + optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35294b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mae_loss(preds, targets, mask):\n",
    "    \"\"\"\n",
    "    preds: (B, M)\n",
    "    targets: (B, M)\n",
    "    mask: (B, M)  -> 1 where target exists, 0 where missing\n",
    "    returns average MAE over observed entries\n",
    "    \"\"\"\n",
    "    diff = torch.abs(preds - targets) * mask\n",
    "    # sum diffs and divide by number of observed elements (avoid zero divide)\n",
    "    denom = mask.sum()\n",
    "    if denom.item() == 0:\n",
    "        return torch.tensor(0.0, device=preds.device)\n",
    "    return diff.sum() / denom\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c50d99",
   "metadata": {},
   "source": [
    "11. Training & validation loop (saves best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575b7836",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val = float(\"inf\")\n",
    "save_path = \"best_fusion_multi.pth\"\n",
    "\n",
    "for epoch in range(1, EPOCHS):\n",
    "    # --- train ---\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    seen = 0\n",
    "    for imgs, tabs, ys, masks in tqdm(train_loader, desc=f\"Epoch {epoch} train\"):\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        tabs = tabs.to(DEVICE)\n",
    "        ys = ys.to(DEVICE)\n",
    "        masks = masks.to(DEVICE)\n",
    "\n",
    "        preds = model(imgs, tabs)  # (B, M)\n",
    "        loss = masked_mae_loss(preds, ys, masks)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_n = imgs.size(0)\n",
    "        train_loss += loss.item() * batch_n\n",
    "        seen += batch_n\n",
    "\n",
    "    train_loss_epoch = train_loss / max(seen,1)\n",
    "\n",
    "    # --- validate ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    seen_val = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, tabs, ys, masks in tqdm(val_loader, desc=f\"Epoch {epoch} val\"):\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            tabs = tabs.to(DEVICE)\n",
    "            ys = ys.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "            preds = model(imgs, tabs)\n",
    "            loss = masked_mae_loss(preds, ys, masks)\n",
    "            batch_n = imgs.size(0)\n",
    "            val_loss += loss.item() * batch_n\n",
    "            seen_val += batch_n\n",
    "\n",
    "    val_loss_epoch = val_loss / max(seen_val,1)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Train MAE={train_loss_epoch:.4f}  Val MAE={val_loss_epoch:.4f}\")\n",
    "\n",
    "    # save best\n",
    "    if val_loss_epoch < best_val:\n",
    "        best_val = val_loss_epoch\n",
    "        torch.save({\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"enc_categories\": enc.categories_,\n",
    "            \"scaler_mean\": scaler.mean_,\n",
    "            \"scaler_scale\": scaler.scale_,\n",
    "            \"tab_dim\": tab_dim,\n",
    "            \"target_names\": TARGET_NAMES\n",
    "        }, save_path)\n",
    "        print(f\"Saved best model to {save_path} (val {best_val:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c05fb",
   "metadata": {},
   "source": [
    "12. Prepare test samples (build per-sample table) and tabular zeros fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9ee72c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4ced0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test tabular shape: (10, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1001187975__Dry_Clover_g</td>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1001187975__Dry_Dead_g</td>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1001187975__Dry_Green_g</td>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1001187975__Dry_Total_g</td>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID1001187975__GDM_g</td>\n",
       "      <td>test/ID1001187975.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sample_id             image_path\n",
       "0  ID1001187975__Dry_Clover_g  test/ID1001187975.jpg\n",
       "1    ID1001187975__Dry_Dead_g  test/ID1001187975.jpg\n",
       "2   ID1001187975__Dry_Green_g  test/ID1001187975.jpg\n",
       "3   ID1001187975__Dry_Total_g  test/ID1001187975.jpg\n",
       "4         ID1001187975__GDM_g  test/ID1001187975.jpg"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw = pd.read_csv(TEST_CSV)\n",
    "test_raw[\"image_path\"] = test_raw[\"image_path\"].astype(str)\n",
    "\n",
    "# Test has one row per sample_id x target_name (like the sample submission)\n",
    "# We need unique sample rows (one image per sample_id)\n",
    "test_samples = test_raw.groupby(\"sample_id\").first().reset_index()[[\"sample_id\", \"image_path\"]]\n",
    "\n",
    "# Build tabular for test: test CSV lacks metadata, so we create zeros for tabular inputs\n",
    "# But we must match the encoder's feature length: date(2) + num(2) + cat(len)\n",
    "date_placeholders = np.zeros((len(test_samples), 2), dtype=np.float32)\n",
    "num_placeholders = np.zeros((len(test_samples), len(num_cols)), dtype=np.float32)\n",
    "# scaled num => zeros (same transform)\n",
    "num_scaled_test = (num_placeholders - scaler.mean_) / scaler.scale_\n",
    "# categorical => zeros (no categories known)\n",
    "cat_dim = sum(len(cats) for cats in enc.categories_)\n",
    "cat_zeros = np.zeros((len(test_samples), cat_dim), dtype=np.float32)\n",
    "\n",
    "tabular_test = np.hstack([date_placeholders, num_scaled_test, cat_zeros]).astype(np.float32)\n",
    "print(\"Test tabular shape:\", tabular_test.shape)\n",
    "test_samples.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e9afe",
   "metadata": {},
   "source": [
    "13. Test dataloader & inference (produce predictions per sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c504cf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from best_fusion_multi.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test infer:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\Robert\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Test infer: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = TestPastureDataset(test_samples, tabular_test, transform=val_transform, img_root=TEST_IMG_ROOT)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
    "\n",
    "# load best model checkpoint if saved\n",
    "if os.path.exists(save_path):\n",
    "    ck = torch.load(save_path, map_location=DEVICE, weights_only=False)\n",
    "    model.load_state_dict(ck[\"model_state_dict\"])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    print(\"Loaded checkpoint from\", save_path)\n",
    "\n",
    "pred_map = {}  # base sample_id -> predicted vector (len TARGET_NAMES)\n",
    "with torch.no_grad():\n",
    "    for imgs, tabs, sample_ids in tqdm(test_loader, desc=\"Test infer\"):\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        tabs = tabs.to(DEVICE)\n",
    "        preds = model(imgs, tabs)  # (B, M)\n",
    "        preds_np = preds.cpu().numpy()\n",
    "        for sid, p in zip(sample_ids, preds_np):\n",
    "            pred_map[sid] = p.copy()\n",
    "\n",
    "len(pred_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ea1262",
   "metadata": {},
   "source": [
    "14. Build submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dddb77e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv with 10 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1001187975__Dry_Clover_g__Dry_Clover_g</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1001187975__Dry_Dead_g__Dry_Dead_g</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1001187975__Dry_Green_g__Dry_Green_g</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1001187975__Dry_Total_g__Dry_Total_g</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID1001187975__GDM_g__GDM_g</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID4464212__Dry_Clover_g__Dry_Clover_g</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID4464212__Dry_Dead_g__Dry_Dead_g</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ID4464212__Dry_Green_g__Dry_Green_g</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ID4464212__Dry_Total_g__Dry_Total_g</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ID4464212__GDM_g__GDM_g</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sample_id  target\n",
       "0  ID1001187975__Dry_Clover_g__Dry_Clover_g    0.39\n",
       "1      ID1001187975__Dry_Dead_g__Dry_Dead_g    1.17\n",
       "2    ID1001187975__Dry_Green_g__Dry_Green_g    1.24\n",
       "3    ID1001187975__Dry_Total_g__Dry_Total_g    1.44\n",
       "4                ID1001187975__GDM_g__GDM_g    0.06\n",
       "5     ID4464212__Dry_Clover_g__Dry_Clover_g    0.06\n",
       "6         ID4464212__Dry_Dead_g__Dry_Dead_g    0.47\n",
       "7       ID4464212__Dry_Green_g__Dry_Green_g    0.46\n",
       "8       ID4464212__Dry_Total_g__Dry_Total_g    0.76\n",
       "9                   ID4464212__GDM_g__GDM_g    0.37"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load sample_submission template if exists to get exact order; otherwise use test_raw order\n",
    "if os.path.exists(SAMPLE_SUBMISSION):\n",
    "    sample_sub = pd.read_csv(SAMPLE_SUBMISSION)\n",
    "    use_template = True\n",
    "else:\n",
    "    # Build template from test_raw: every row in test_raw corresponds to a sample_id__target_name row\n",
    "    # test_raw already has sample_id and target_name rows\n",
    "    sample_sub = test_raw[[\"sample_id\", \"target_name\"]].copy()\n",
    "    # Build full sample_id column: sample_id__target_name\n",
    "    sample_sub[\"sample_id_full\"] = sample_sub[\"sample_id\"].astype(str) + \"__\" + sample_sub[\"target_name\"].astype(str)\n",
    "    sample_sub = sample_sub[[\"sample_id_full\"]].rename(columns={\"sample_id_full\": \"sample_id\"})\n",
    "    sample_sub[\"target\"] = 0.0\n",
    "    use_template = False\n",
    "\n",
    "# If using a template with combined sample_id like \"ID1001187975__Dry_Clover_g\"\n",
    "if use_template:\n",
    "    out_rows = []\n",
    "    for idx, row in sample_sub.iterrows():\n",
    "        full_id = row[\"sample_id\"]\n",
    "        # extract base sample id (before __)\n",
    "        base = full_id.split(\"__\")[0]\n",
    "        tname = full_id.split(\"__\")[1] if \"__\" in full_id else None\n",
    "        pred_vec = pred_map.get(base)\n",
    "        if pred_vec is None:\n",
    "            # fallback: 0\n",
    "            pred_val = 0.0\n",
    "        else:\n",
    "            if tname is None:\n",
    "                pred_val = 0.0\n",
    "            else:\n",
    "                # map tname to index in TARGET_NAMES\n",
    "                try:\n",
    "                    tidx = TARGET_NAMES.index(tname)\n",
    "                    pred_val = float(pred_vec[tidx])\n",
    "                except ValueError:\n",
    "                    pred_val = 0.0\n",
    "        out_rows.append((full_id, pred_val))\n",
    "    submission_df = pd.DataFrame(out_rows, columns=[\"sample_id\", \"target\"])\n",
    "else:\n",
    "    # sample_sub was built from test_raw order, sample_id column is like base; we need full form\n",
    "    out_rows = []\n",
    "    for idx, row in test_raw.iterrows():\n",
    "        base = row[\"sample_id\"]\n",
    "        tname = row[\"target_name\"]\n",
    "        pred_vec = pred_map.get(base)\n",
    "        if pred_vec is None:\n",
    "            pred_val = 0.0\n",
    "        else:\n",
    "            try:\n",
    "                tidx = TARGET_NAMES.index(tname)\n",
    "                pred_val = float(pred_vec[tidx])\n",
    "            except ValueError:\n",
    "                pred_val = 0.0\n",
    "        full_id = f\"{base}__{tname}\"\n",
    "        out_rows.append((full_id, pred_val))\n",
    "    submission_df = pd.DataFrame(out_rows, columns=[\"sample_id\", \"target\"])\n",
    "\n",
    "# Optional: clip negative predictions to zero\n",
    "submission_df[\"target\"] = submission_df[\"target\"].clip(lower=0.0)\n",
    "\n",
    "# Round to 2 decimals\n",
    "submission_df[\"target\"] = submission_df[\"target\"].round(2)\n",
    "\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Saved submission.csv with\", len(submission_df), \"rows\")\n",
    "submission_df.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
